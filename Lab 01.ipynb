{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EbChgA_YjumN"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE, Laplace, KneserNeyInterpolated"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPTz9SDQj7ed",
        "outputId": "6c645759-be8b-40be-91de-6510865601d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training corpus\n",
        "corpus = [\n",
        "    \"Tôi thích học máy và xử lý ngôn ngữ tự nhiên\",\n",
        "    \"Ngôn ngữ tự nhiên là một lĩnh vực thú vị\",\n",
        "    \"Chúng ta có thể sử dụng mô hình n-gram để xử lý văn bản\",\n",
        "    \"Xử lý ngôn ngữ tự nhiên rất quan trọng trong AI\"\n",
        "]\n",
        "\n",
        "# Preprocess: tokenize\n",
        "tokenized_text = [word_tokenize(sent.lower()) for sent in corpus]"
      ],
      "metadata": {
        "id": "3wB6FP9rjxXN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 3  # n-gram"
      ],
      "metadata": {
        "id": "42ZVRvLrj0cx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Maximum Likelihood Estimation\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, tokenized_text)\n",
        "model_mle = MLE(n)\n",
        "model_mle.fit(train_data, padded_vocab)"
      ],
      "metadata": {
        "id": "qEUM_VKjkE12"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Smoothing with Laplace\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, tokenized_text)\n",
        "model_laplace = Laplace(n)\n",
        "model_laplace.fit(train_data, padded_vocab)"
      ],
      "metadata": {
        "id": "eCQ3UGwckIty"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Kneser-Ney smoothing (discounting + backoff + interpolation)\n",
        "train_data, padded_vocab = padded_everygram_pipeline(n, tokenized_text)\n",
        "model_kn = KneserNeyInterpolated(n)\n",
        "model_kn.fit(train_data, padded_vocab)"
      ],
      "metadata": {
        "id": "iGOdC1fQkKSb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the next token for \"xử lý\"\n",
        "context = ['xử', 'lý']\n",
        "\n",
        "print(\"MLE:\", model_mle.generate(1, text_seed=context))\n",
        "print(\"Laplace:\", model_laplace.generate(1, text_seed=context))\n",
        "print(\"Kneser-Ney:\", model_kn.generate(1, text_seed=context))\n",
        "\n",
        "# Compute the probability P(w|\"xử lý\")\n",
        "print(\"\\nP('ngôn' | 'xử lý'):\", model_kn.score('ngôn', ['xử', 'lý']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTQRpf2bkLTF",
        "outputId": "165e78d0-148a-4d49-f901-0fc5e643d97f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLE: văn\n",
            "Laplace: ngôn\n",
            "Kneser-Ney: văn\n",
            "\n",
            "P('ngôn' | 'xử lý'): 0.6636434108527132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without NLTK"
      ],
      "metadata": {
        "id": "_0KdJ2u30roA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentences(corpus):\n",
        "    return [sentence.lower().split() for sentence in corpus]\n",
        "\n",
        "def generate_ngrams(tokens, n):\n",
        "    padded = ['<s>'] * (n - 1) + tokens + ['</s>']\n",
        "    return [tuple(padded[i:i + n]) for i in range(len(padded) - n + 1)]"
      ],
      "metadata": {
        "id": "ZiQzz3020hg-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, Counter\n",
        "\n",
        "def count_ngrams(tokenized_sentences, n):\n",
        "    ngram_counts = defaultdict(Counter)\n",
        "    for sentence in tokenized_sentences:\n",
        "        ngrams = generate_ngrams(sentence, n)\n",
        "        for gram in ngrams:\n",
        "            context = gram[:-1]\n",
        "            word = gram[-1]\n",
        "            ngram_counts[context][word] += 1\n",
        "    return ngram_counts"
      ],
      "metadata": {
        "id": "x-RtuEyZ0h40"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenize_sentences(corpus)\n",
        "\n",
        "unigram = count_ngrams(tokenized, 1)\n",
        "bigram = count_ngrams(tokenized, 2)\n",
        "trigram = count_ngrams(tokenized, 3)"
      ],
      "metadata": {
        "id": "uWdPgy9a0kXm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTt6nIhi1xLM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x2F1TnJW4vEs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}